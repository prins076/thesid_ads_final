{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\snell\\anaconda3\\envs\\thesis_env\\lib\\site-packages\\whisper\\timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import whisper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/audios/'\n",
    "DATASET_FILES = glob(DATASET_PATH + '*.mp3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [02:55<00:00, 8.72MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1185 [00:00<?, ?it/s]c:\\Users\\snell\\anaconda3\\envs\\thesis_env\\lib\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "100%|██████████| 1185/1185 [12:27:08<00:00, 37.83s/it]   \n"
     ]
    }
   ],
   "source": [
    "final_dataset = []\n",
    "\n",
    "for audio_file in tqdm(DATASET_FILES):\n",
    "    audio_data = {}\n",
    "    audio_path = audio_file\n",
    "    audio_id = audio_path.replace(DATASET_PATH, '').replace('.mp3', '')\n",
    "    audio_id = audio_id.split('\\\\')[-1]  # Extract numbers after final '\\'\n",
    "    \n",
    "    audio = whisper.load_audio(audio_file)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    \n",
    "    _, probs = model.detect_language(mel)\n",
    "    detected_language = max(probs, key=probs.get)\n",
    "    \n",
    "    result = model.transcribe(audio_path)\n",
    "    \n",
    "    audio_data['audio_id'] = audio_id\n",
    "    audio_data['transcription'] = result[\"text\"].strip()\n",
    "    audio_data['detected_language'] = detected_language\n",
    "    \n",
    "    final_dataset.append(audio_data)\n",
    "    \n",
    "final_dataset_df = pd.DataFrame.from_dict(final_dataset)\n",
    "final_dataset_df.to_csv('transcripted_audios.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
